import 'dart:io';
import 'package:record/record.dart';
import 'package:path_provider/path_provider.dart';
import 'package:ffmpeg_kit_flutter/ffmpeg_kit.dart';
import 'package:ffmpeg_kit_flutter/return_code.dart';

class CallRecordingService {
  final _recorder = AudioRecorder();
  String? _currentFilePath;

  Future<void> startRecording() async {
    final hasPermission = await _recorder.hasPermission();
    if (!hasPermission) {
      throw Exception('ğŸ™ï¸ Microphone permission denied');
    }

    final dir = await getApplicationDocumentsDirectory();
    final filePath = '${dir.path}/conversation_${DateTime.now().millisecondsSinceEpoch}.wav';
    _currentFilePath = filePath;

    final config = RecordConfig(
      encoder: AudioEncoder.wav,
      bitRate: 128000,
      sampleRate: 44100,
    );

    await _recorder.start(
      config,
      path: filePath,
    );
  }

  Future<String?> stopRecording() async {
    if (await _recorder.isRecording()) {
      await _recorder.stop();
      return _currentFilePath;
    }
    return null;
  }

  Future<bool> isRecording() async => await _recorder.isRecording();

  Future<String?> mergeAudioFiles({
    required String micPath,
    required List<String> ttsPaths,
    required String outputFileName,
  }) async {
    final outputDir = (await getApplicationDocumentsDirectory()).path;
    final outputPath = '$outputDir/$outputFileName.wav';
    final listPath = '$outputDir/concat_list.txt';

    // í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
    final buffer = StringBuffer();
    buffer.writeln("file '$micPath'");
    for (final path in ttsPaths) {
      buffer.writeln("file '$path'");
    }
    await File(listPath).writeAsString(buffer.toString());

    // ffmpeg ì‹¤í–‰
    final session = await FFmpegKit.execute(
      "-f concat -safe 0 -i $listPath -c copy $outputPath",
    );

    final returnCode = await session.getReturnCode();
    if (ReturnCode.isSuccess(returnCode)) {
      print("âœ… ë³‘í•© ì™„ë£Œ: $outputPath");
      return outputPath;
    } else {
      print("âŒ ë³‘í•© ì‹¤íŒ¨: ${returnCode?.getValue()}");
      return null;
    }
  }


  Future<void> deleteAudioResources({
    required String micPath,
    required List<String> ttsPaths,
  }) async {
    try {
      // ğŸ¤ ë§ˆì´í¬ ë…¹ìŒ íŒŒì¼ ì‚­ì œ
      final micFile = File(micPath);
      if (await micFile.exists()) {
        await micFile.delete();
        print('ğŸ—‘ï¸ ë§ˆì´í¬ íŒŒì¼ ì‚­ì œë¨: $micPath');
      }

      // ğŸ§  TTS íŒŒì¼ë“¤ ì‚­ì œ
      for (final path in ttsPaths) {
        final ttsFile = File(path);
        if (await ttsFile.exists()) {
          await ttsFile.delete();
          print('ğŸ—‘ï¸ TTS íŒŒì¼ ì‚­ì œë¨: $path');
        }
      }
    } catch (e) {
      print('âŒ ì˜¤ë””ì˜¤ íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜: $e');
    }
  }
}